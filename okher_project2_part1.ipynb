{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells":
      "metadata": {
        "id": "Bw9ujOG4xRie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the current directory to google drive path where the video is stored.\n"
      ],
      "metadata": {
        "id": "aDHi2Nxxxd3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN0a1b32ypte",
        "outputId": "705fcf87-9122-4728-f1c2-a255930fb133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing the specific folder in which the video has been stored."
      ],
      "metadata": {
        "id": "KkKT-EtQxn9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_folder = \"ENPM673/Project2/\"\n",
        "%cd /content/drive/My\\ Drive/{path_to_folder}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Q8Q3E-yqgM",
        "outputId": "e21182df-f3b1-4e2f-bc41-4272bbc12dfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ENPM673/Project2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video Processing piepline."
      ],
      "metadata": {
        "id": "hBFB1HZhxs3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow  # For displaying images in Colab\n",
        "\n",
        "def variance_of_laplacian(gray_frame):    #Manually applying the laplacian kernel to find out the spike in intensity of the frames captured from the video to detect edges.\n",
        "    laplacian_kernel = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
        "    laplacian = cv2.filter2D(gray_frame, -1, laplacian_kernel)\n",
        "    return np.var(laplacian)    #Returning the variance of each frame (low variance indicates less sharpness, high variance indicates sharp frames)\n",
        "\n",
        "def line_length(line):      #Defining a function to compute the length of a line so obtained from Hough transform.\n",
        "    x1, y1, x2, y2 = line[0]\n",
        "    return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "def find_intersection(line1, line2):      #Defining a function to find the intersection of any two lines to detect corners.\n",
        "    # Calculating the determinants\n",
        "    x1, y1, x2, y2 = line1[0]\n",
        "    x3, y3, x4, y4 = line2[0]\n",
        "    det = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
        "\n",
        "    if det == 0:\n",
        "        return None  # Lines are parallel, no intersection\n",
        "\n",
        "    # Calculating the x, y intersection coordinates (corner coordinates)\n",
        "    det_inv = 1 / det\n",
        "    x = det_inv * ((x1*y2 - y1*x2) * (x3 - x4) - (x1 - x2) * (x3*y4 - y3*x4))\n",
        "    y = det_inv * ((x1*y2 - y1*x2) * (y3 - y4) - (y1 - y2) * (x3*y4 - y3*x4))\n",
        "\n",
        "    return (int(x), int(y))\n",
        "\n",
        "video_path = 'Source/proj2_v2.mp4'   #Accessing the video file from inside folder\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "sharp_frames_count = 0    #Initialising counts for sharp and blurry frames\n",
        "blurry_frames_count = 0\n",
        "threshold_sharpness = 53    #Setting the threshold for sharpness as 53 which satisfies the condition of keeping more than 50% of the frames in the output video.\n",
        "threshold_white = 220       #Setting the threshold for detecting white objects.\n",
        "\n",
        "# Parameters for Hough Line Transform\n",
        "rho = 1\n",
        "theta = np.pi / 180\n",
        "threshold_hough = 50\n",
        "min_line_length = 115\n",
        "max_line_gap = 10\n",
        "\n",
        "# Parameters for Harris corner detection\n",
        "block_size = 2\n",
        "ksize = 3\n",
        "k = 0.04\n",
        "\n",
        "# Define the codec and create VideoWriter object to save the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec definition\n",
        "output_path = 'Source/output_proj2_v2.mp4'  # Define a new path for the output video\n",
        "out = cv2.VideoWriter(output_path, fourcc, 10.0, (int(cap.get(3)), int(cap.get(4))))    #Output video in 10fps.\n",
        "\n",
        "\n",
        "# Processing loop\n",
        "while True:\n",
        "    ret, frame = cap.read()   #To extract frames from the video.\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    #Converting all the frames to grayscale\n",
        "    sharpness = variance_of_laplacian(gray_frame)     #Calculating the sharpness of each frame\n",
        "\n",
        "    #Conditonal to separate the sharp frames from the blurry frames\n",
        "    if sharpness > threshold_sharpness:\n",
        "        sharp_frames_count += 1\n",
        "        _, white_regions = cv2.threshold(gray_frame, threshold_white, 255, cv2.THRESH_BINARY)   #Applying threshold to convert segment out the white region from all other regions.\n",
        "        edges = cv2.Canny(white_regions, 150, 450)    #Using canny edge detector to find out the edges\n",
        "\n",
        "        lines = cv2.HoughLinesP(edges, rho, theta, threshold_hough, minLineLength=min_line_length, maxLineGap=max_line_gap)   #Using HoughLinesP a probabilistic function to detect straight lines which can be the edges of the paper in the video (putative edges of the paper).\n",
        "\n",
        "        if lines is not None:\n",
        "            dominant_lines = [line for line in lines if line_length(line) > min_line_length]    #Separating out all the short lines(noise) from the long lines (paper edges)\n",
        "\n",
        "            for line in dominant_lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "            intersections = []\n",
        "            for i, line1 in enumerate(dominant_lines):\n",
        "                for line2 in dominant_lines[i+1:]:\n",
        "                    intersect = find_intersection(line1, line2)\n",
        "                    if intersect:\n",
        "                        intersections.append(intersect)\n",
        "\n",
        "\n",
        "            # Applying the Harris corner detection\n",
        "            harris_corners = cv2.cornerHarris(np.float32(gray_frame), block_size, ksize, k)\n",
        "            harris_corners = cv2.dilate(harris_corners, None)\n",
        "\n",
        "\n",
        "            #Thresholding to get the coordinates of the Harris corners\n",
        "            corners = np.where(harris_corners > 0.01 * harris_corners.max())\n",
        "            corners = list(zip(*corners[::-1]))  # Reversing to (x,y) and make a list of tuples\n",
        "\n",
        "            # Verifying if Hough intersections are close to Harris corners\n",
        "            for intersect in intersections:\n",
        "              x, y = intersect\n",
        "              if any(np.linalg.norm(np.array(intersect) - np.array(corner)) < 10 for corner in corners):\n",
        "                # This intersection is verified by Harris, mark it\n",
        "                cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)  # Mark verified corners in red\n",
        "\n",
        "\n",
        "        out.write(frame)  # Write the processed frame to the output video\n",
        "\n",
        "    else:\n",
        "        blurry_frames_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(f\"Total sharp (non-blurry) frames: {sharp_frames_count}\")\n",
        "print(f\"Total number of blurry frames skipped: {blurry_frames_count}\")\n",
        "print(\"Output video has been generated in the location where the input video is stored in Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSMQOaElyqi8",
        "outputId": "a166a100-c7c7-40b3-9652-c78336237c60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sharp (non-blurry) frames: 199\n",
            "Total number of blurry frames skipped: 187\n",
            "Output video has been generated in the location where the input video is stored in Google Drive.\n"
          ]
        }
      ]
    }
  ]
}
